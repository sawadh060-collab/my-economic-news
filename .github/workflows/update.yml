name: Super Fast News Update

on:
  schedule:
    # This runs every 5 minutes (the fastest GitHub allows)
    - cron: '*/5 * * * *'
  workflow_dispatch: # This adds a manual "Run" button for you to test

jobs:
  build:
    runs-on: ubuntu-latest
    
    # This is the "Key" that lets the robot write to your data.json file
    permissions:
      contents: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          
      - name: Install Scraper Tools
        run: pip install requests beautifulsoup4
        
      - name: Run the Scraper
        run: python scrape.py
        
      - name: Save and Push News
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"
          git add data.json
          # This line prevents errors if the news hasn't changed
          git commit -m "Auto-update: Fresh News" || exit 0
          git push
